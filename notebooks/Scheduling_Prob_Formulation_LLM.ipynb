{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17058544-8ee1-4934-aa4a-056b5164f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import re\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm  \n",
    "import pandas as pd\n",
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df06826-361d-4b74-9f2a-63545ba7a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# Add open-ai credentials. This project uses azure openAI service\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"...\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7289fb1-415f-4cdb-9f15-a063889c0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aoai models - add the azure openai deployment instance names\n",
    "\n",
    "aoai_gpt4o=\"...\"\n",
    "aoai_gpt4o_mv=\"2023-07-01-preview\" # need to be updated based on new model API version release\n",
    "aoai_embeddings=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9816ec67-0ff7-405e-8356-06af2f260c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call using AzureChatOpenAI - Langchain\n",
    "aoai_llm = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=aoai_gpt4o,\n",
    "    model_version=aoai_gpt4o_mv\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7396f7f3-4179-4cd7-bff4-ef30657a9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_python_code(markdown_text):  \n",
    "    # Regular expression pattern for a Python code block in Markdown  \n",
    "    # This pattern looks for both ```python and ``` followed by the code block  \n",
    "    pattern = r'```(?:python)?\\s*(.*?)```'  \n",
    "      \n",
    "    # Use re.DOTALL to match across multiple lines  \n",
    "    matches = re.findall(pattern, markdown_text, re.DOTALL)  \n",
    "      \n",
    "    # If code blocks are found, join them; otherwise, return the entire text assuming it's Python code  \n",
    "    if matches:  \n",
    "        # Join matches in case there are multiple code blocks  \n",
    "        python_code = '\\n\\n'.join(matches)  \n",
    "    else:  \n",
    "        # If no markdown code blocks are detected, assume the entire text is Python code  \n",
    "        python_code = markdown_text  \n",
    "      \n",
    "    return python_code  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "039d9d16-28ca-4da8-84b1-39ac8f965f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_curly_braces(text):  \n",
    "    # Define the regular expression pattern for {some exp}  \n",
    "    # The pattern looks for an opening curly brace, followed by  \n",
    "    # any characters that are not a closing curly brace (non-greedy),  \n",
    "    # followed by a closing curly brace  \n",
    "    pattern = r'({[^}]*})'  \n",
    "      \n",
    "    # Use the re.sub function to replace the pattern with doubled curly braces  \n",
    "    # The replacement pattern uses \\1 to refer to the matched text within the curly braces  \n",
    "    replaced_text = re.sub(pattern, r'{\\1}', text, flags=re.DOTALL)\n",
    "      \n",
    "    return replaced_text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afa9d1a-ca8e-4987-927f-175c091e3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./data/Schedule_Data_Train.csv\")\n",
    "data_val = pd.read_csv(\"./data/Schedule_Data_Val.csv\")\n",
    "data_test = pd.read_csv(\"./data/Schedule_Data_Test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23235db4-70d2-4fef-b180-0a1a067d07e4",
   "metadata": {},
   "source": [
    "## [A1] GPT4 with Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b4e3e7-a1d0-441d-ac41-0397cef61918",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_prompt_template = \"\"\" You are an AI assistant with expertise in creating python problem formulation for a given job shop scheduling problem description.\n",
    "I will provide you a job scheduling problem description and you goal is the answer the problem formulation in python. \n",
    "The answer you provide will be passed to a constraint programming solver(cpmpy library) to validate the problem formulation you provide.\n",
    "So, revisit the problem formulation step by step to validate any syntax or logical errors and only output the valid python code for the problem formulation with no additional text and description.\n",
    "\n",
    "If you don't know answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Input: {input}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "zs_prompt = PromptTemplate.from_template(zs_prompt_template)\n",
    "\n",
    "zs_rag_chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | zs_prompt\n",
    "    | aoai_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ddb5d2-d676-4ed5-8493-394a0fcb1749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [05:48<00:00, 17.40s/iteration]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to the DataFrame for storing responses  \n",
    "data_test['pf_gpt_zs'] = None  \n",
    "\n",
    "# Define the number of iterations in your loop  \n",
    "total_iterations = len(data_test)  \n",
    "  \n",
    "# Use tqdm to create a progress bar  \n",
    "progress_bar = tqdm(total=total_iterations, desc='Processing', unit='iteration')  \n",
    "  \n",
    "total_cost = 0  \n",
    "  \n",
    "for index, row in data_test.iterrows():  \n",
    "    prob_desc = row[\"Description\"]  \n",
    "    with get_openai_callback() as cb:  \n",
    "        response = zs_rag_chain.invoke(prob_desc)\n",
    "        prob_form = extract_python_code(response)\n",
    "        data_test.at[index, 'pf_gpt_zs'] = prob_form  \n",
    "        total_cost += cb.total_cost\n",
    "    #print(f\"cost: ${format(cb.total_cost, '.6f')}\")\n",
    "    time.sleep(1)  \n",
    "    progress_bar.update(1)\n",
    "  \n",
    "progress_bar.close()  \n",
    "  \n",
    "#print(f\"Total cost: ${format(total_cost, '.6f')}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe02fb8d-9cf7-40f8-af00-ad75d0257dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the updated DataFrame to a new CSV file  \n",
    "data_test.to_csv(\"./data/results_analysis6.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430a55e-3e77-492e-854b-2f96a59b7bac",
   "metadata": {},
   "source": [
    "## [A2] GPT4 with One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2879b60a-9202-44c7-9943-0c0ad04267ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_train.iloc[15][\"Description\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5511d04-10fb-4106-8e7b-51b846d83cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_prompt_template_s = f\"\"\" You are an AI assistant with expertise in creating python problem formulation for a given job shop scheduling problem description.\n",
    "I will provide you a job scheduling problem description and you goal is the answer the problem formulation in python. \n",
    "The answer you provide will be passed to a constraint programming solver(cpmpy library) to validate the problem formulation you provide.\n",
    "So, revisit the problem formulation step by step to validate any syntax or logical errors and only output the valid python code for the problem formulation with no additional text and description.\n",
    "If you don't know answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Example:\n",
    "Input: {data_train.iloc[15][\"Description\"]}  \n",
    "Output: \n",
    "{double_curly_braces(data_train.iloc[15][\"Prob_Formulation\"])} \n",
    "\"\"\"\n",
    "os_template_suffix = \"\"\"\n",
    "Input: {input}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "os_prompt_template = os_prompt_template_s + os_template_suffix\n",
    "\n",
    "os_prompt = PromptTemplate.from_template(os_prompt_template)\n",
    "\n",
    "os_rag_chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | os_prompt\n",
    "    | aoai_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e02e4449-9f37-4d33-86bc-e0ba59fa94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78a07ec-eefd-45b4-8ad8-262adca5a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [10:49<00:00, 32.48s/iteration]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to the DataFrame for storing responses  \n",
    "data_test['pf_gpt_os'] = None  \n",
    "\n",
    "# Define the number of iterations in your loop  \n",
    "# total_iterations = len(data_test)  \n",
    "  \n",
    "# Use tqdm to create a progress bar  \n",
    "progress_bar2 = tqdm(total=total_iterations, desc='Processing', unit='iteration')  \n",
    "  \n",
    "total_cost = 0  \n",
    "  \n",
    "for index, row in data_test.iterrows():  \n",
    "    prob_desc = row[\"Description\"]  \n",
    "    with get_openai_callback() as cb:  \n",
    "        response = os_rag_chain.invoke(prob_desc)\n",
    "        prob_form = extract_python_code(response)\n",
    "        data_test.at[index, 'pf_gpt_os'] = prob_form  \n",
    "        total_cost += cb.total_cost\n",
    "    #print(f\"cost: ${format(cb.total_cost, '.6f')}\")\n",
    "    time.sleep(1)  \n",
    "    progress_bar2.update(1)\n",
    "  \n",
    "progress_bar2.close()  \n",
    "  \n",
    "#print(f\"Total cost: ${format(total_cost, '.6f')}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d808884-426d-4e40-85eb-d23c32e97614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the updated DataFrame to a new CSV file  \n",
    "data_test.to_csv(\"./data/results_analysis6.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319d523-1e68-468c-9644-38bf52016431",
   "metadata": {},
   "source": [
    "## [A3] GPT4 with FewShot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2908fd4e-cd21-4534-b942-c2cad4ac504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='./data/Schedule_Data_Train.csv')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1d87f6-fea3-4b6c-8030-75e32d68ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"IKEA-CS-text-embedding-ada-002\",\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets.\n",
    "# retriever = vectorstore.as_retriever()\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e992b86-0300-46a5-91a6-68b78f6ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f8fc78-130c-4414-92f1-7ede345ee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = retriever.invoke(\"Create job shop scheduling model with 7 jobs and 7 machines. All jobs have random routes and their operations have random durations. The due dates are calculated based on a total processing time of each job multiplied by a due date allowance of 1.3. Release time of a job is a random value from 0 to 50. Jobs cannot start before their release times. Each job has a weight following a random distribution in which 20% will have weight of 1, 60% will have weight of 2, and 20% will have weight of 4. The objective function is total weighted flowtime. Maximum duration is 20. After solving the problem, solutions will be printed and visualized. Note: The first task related to each job should be completed before the completion of any job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a7547bf-19bd-4fc3-8744-c10134f71ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_prompt_template = \"\"\" You are an AI assistant with expertise in creating python problem formulation for a given job shop scheduling problem description.\n",
    "I will provide you a job scheduling problem description and you goal is the answer the problem formulation in python. \n",
    "The answer you provide will be passed to a constraint programming solver(cpmpy library) to validate the problem formulation you provide.\n",
    "So, revisit the problem formulation step by step to validate any syntax or logical errors and only output the valid python code for the problem formulation with no additional text and description.\n",
    "\n",
    "If you don't know answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Description: {input}\n",
    "\n",
    "Prob_formulation:\"\"\"\n",
    "\n",
    "fs_prompt = PromptTemplate.from_template(fs_prompt_template)\n",
    "\n",
    "fs_rag_chain = (\n",
    "    {\"examples\": RunnablePassthrough(), \"input\": RunnablePassthrough()}\n",
    "    | fs_prompt\n",
    "    | aoai_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eea77993-69b5-49e2-8fe3-fc61f96df779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fs_rag_chain)\n",
    "# fs_rag_chain.invoke({\"examples\": examples, \"input\": data_test.iloc[0][\"Description\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d300e44-9ce5-492d-b3e1-e7fa961e0d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 20/20 [10:15<00:00, 30.75s/iteration]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to the DataFrame for storing responses  \n",
    "data_test['pf_gpt_fs_rag'] = None  \n",
    "\n",
    "# Define the number of iterations in your loop  \n",
    "# total_iterations = len(data_test)  \n",
    "  \n",
    "# Use tqdm to create a progress bar  \n",
    "progress_bar3 = tqdm(total=total_iterations, desc='Processing', unit='iteration')  \n",
    "  \n",
    "total_cost = 0  \n",
    "  \n",
    "for index, row in data_test.iterrows():  \n",
    "    prob_desc = row[\"Description\"]\n",
    "    matched_examples =  retriever.invoke(prob_desc)\n",
    "    fs_prompt_examples = format_docs(matched_examples)\n",
    "    with get_openai_callback() as cb:  \n",
    "        response = fs_rag_chain.invoke({\"examples\": fs_prompt_examples, \"input\": prob_desc})\n",
    "        prob_form = extract_python_code(response)\n",
    "        data_test.at[index, 'pf_gpt_fs_rag'] = prob_form  \n",
    "        total_cost += cb.total_cost\n",
    "    #print(f\"cost: ${format(cb.total_cost, '.6f')}\")\n",
    "    time.sleep(1)  \n",
    "    progress_bar3.update(1)\n",
    "  \n",
    "progress_bar3.close()  \n",
    "  \n",
    "#print(f\"Total cost: ${format(total_cost, '.6f')}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d32bf1-3229-4380-97af-169cd2e96671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the updated DataFrame to a new CSV file  \n",
    "data_test.to_csv(\"./data/results_analysis6.csv\", index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
